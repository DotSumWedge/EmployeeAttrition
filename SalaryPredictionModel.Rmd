---
title: "SalaryPredictionModel"
author: "DerekRogers"
date: "2022-12-03"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Loading Data From S3 URL Using RCurl
```{r}
library("RCurl") 
library(jsonlite)
library(ggplot2)
library(class)
library(caret)
library(e1071)
library(dplyr)
library(tidyverse)
library(aws.s3)
library(gtools)

creativity <- read.table(textConnection(getURL(
  "https://smuds6306.s3.us-east-2.amazonaws.com/Creativity.csv"
)), sep=",", header=TRUE)

iris3 <- jsonlite::fromJSON("https://smuds6306.s3.us-east-2.amazonaws.com/iris.json")

climate <- read.table(textConnection(getURL(
  "https://cgiardata.s3-us-west-2.amazonaws.com/ccafs/amzn.csv"
)), sep=",", header=TRUE)
```
           
```{r}
Sys.setenv("AWS_ACCESS_KEY_ID" = "AKIAVW4VHW4VPB7MHZWA",
           "AWS_SECRET_ACCESS_KEY" = "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",
           "AWS_DEFAULT_REGION" = "us-east-2")
```

```{r}
# Using aws.s3
aws.s3::bucketlist()
aws.s3::get_bucket("smuddsproject2")

#Read in Creativity.csv
turnoverDataframe = s3read_using(FUN = read.csv,
                    bucket = "smuddsproject2",
                    object = "CaseStudy2-data.csv")

testAttritionTurnoverDataframe = s3read_using(FUN = read.csv,
                    bucket = "smuddsproject2",
                    object = "CaseStudy2CompSet No Attrition.csv")

testSalaryDataframe =  s3read_using(FUN = read.csv,
                    bucket = "smuddsproject2",
                    object = "CaseStudy2CompSet No Salary.xlsx")

noSalaryDataframeCSV = data.frame(read.csv("C:/SMU MS Data Science/DoingDataScience6306/EmployeeAttrition/CaseStudy2CompSet_No_Salary.csv"))

turnoverDataframe$Attrition = as.factor(turnoverDataframe$Attrition)
turnoverDataframe$JobLevel = as.factor(turnoverDataframe$JobLevel)
testSalaryDataframe
```

```{r}
# Remove columns with no unique values: Over18, EmployeeCount, StandardHours
# Remove employee number as it is only used as a unique identifier and not useful for attrition analysis
dropColumns = c("Over18", "StandardHours", "EmployeeCount", "EmployeeNumber")
turnoverDataframe = turnoverDataframe[ , !(names(turnoverDataframe) %in% dropColumns)]
```

```{r}
# Reorder so Attrition is the first column, ID is the second column, and Age is the 3rd column
# Only keep numeric columns
turnoverDataframe = turnoverDataframe[,c(3,1,2,5,7,8,10,12,13,14,16,18,19,20,22,23,24,25,26,27,28,29,30,31,32)]

apply(turnoverDataframe, 2, function(x) length(unique(x)))
ncol(turnoverDataframe)
```

```{r}
ncol(turnoverDataframe)
turnoverDataframe$LogMonthlyIncome = log(turnoverDataframe$MonthlyIncome)
turnoverDataframe
```

```{r}
#Columns that probably predict salary:
# Education
# HourlyRate
# JobInvolvement
# JobLevel
# MonthlyRate
# PercentSalaryHike
# PerformanceRating
# StockOptionLevel
# ??? YearsAtCompany - YearsSinceLastPromotion
```

```{r}
model = lm(LogMonthlyIncome~JobLevel, turnoverDataframe)

summary(model)
```

```{r}
turnoverDataframe %>% ggplot(aes(x = JobLevel, y = MonthlyIncome, color = JobLevel)) + 
  geom_point() +
  labs(title="Monthly Income by Job Level")
```

```{r}
turnoverDataframe %>% ggplot(aes(x=JobLevel, y=MonthlyIncome, color = JobLevel)) + 
  geom_boxplot() + 
  labs(y="Monthly Income", 
       x="Job Level", 
       title="Monthly Income by Job Level")
```

```{r}
noSalaryDataframeCSV
noSalaryDataframeCSV$JobLevel = as.factor(noSalaryDataframeCSV$JobLevel)

predMonthlyIncomes = predict(model, newdata = noSalaryDataframeCSV)

pred_df = as.data.frame(predMonthlyIncomes,noSalaryDataframeCSV)
pred_df$ID = noSalaryDataframeCSV[,1]
pred_df$finalMonthlyIncomePrediction = exp(pred_df$predMonthlyIncomes)

dropColumns = c("predMonthlyIncomes")
pred_df = pred_df[ , !(names(pred_df) %in% dropColumns)]

fileLocation = paste("C:/SMU MS Data Science/DoingDataScience6306/EmployeeAttrition/Predictions/SalaryPrediction.csv", sep="")
write.csv(pred_df, fileLocation, row.names = TRUE)

pred_df
```

```{r}

```

```{r}

```

```{r}

```