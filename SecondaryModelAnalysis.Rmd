---
title: "SecondaryModelAnalysis"
author: "Derek Rogers"
date: "2022-12-05"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Loading Data From S3 URL Using RCurl
```{r}
library("RCurl") 
library(jsonlite)
library(ggplot2)
library(class)
library(caret)
library(e1071)
library(dplyr)
library(tidyverse)
library(aws.s3)
library(gtools)
library(openxlsx)

creativity <- read.table(textConnection(getURL(
  "https://smuds6306.s3.us-east-2.amazonaws.com/Creativity.csv"
)), sep=",", header=TRUE)

iris3 <- jsonlite::fromJSON("https://smuds6306.s3.us-east-2.amazonaws.com/iris.json")

climate <- read.table(textConnection(getURL(
  "https://cgiardata.s3-us-west-2.amazonaws.com/ccafs/amzn.csv"
)), sep=",", header=TRUE)
```
           
```{r}
Sys.setenv("AWS_ACCESS_KEY_ID" = "AKIAVW4VHW4VPB7MHZWA",
           "AWS_SECRET_ACCESS_KEY" = "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",
           "AWS_DEFAULT_REGION" = "us-east-2")
```

```{r}
# Using aws.s3
aws.s3::bucketlist()
aws.s3::get_bucket("smuddsproject2")

#Read in Creativity.csv
turnoverDataframe = s3read_using(FUN = read.csv,
                    bucket = "smuddsproject2",
                    object = "CaseStudy2-data.csv")

noAttritionDataframe = s3read_using(FUN = read.csv,
                    bucket = "smuddsproject2",
                    object = "CaseStudy2CompSet No Attrition.csv")

turnoverDataframe$Attrition = as.factor(turnoverDataframe$Attrition)

noSalaryDataframeCSV = data.frame(read.csv("C:/SMU MS Data Science/DoingDataScience6306/EmployeeAttrition/CaseStudy2CompSet_No_Salary.csv"))
```
```{r}
turnoverDataframe
noAttritionDataframe
noSalaryDataframeCSV

combinedEmployeeDataframe = merge(x = turnoverDataframe, noSalaryDataframeCSV, all = TRUE)

combinedEmployeeDataframe
```

```{r}
# Remove columns with no unique values: Over18, EmployeeCount, StandardHours
# Remove employee number as it is only used as a unique identifier and not useful for attrition analysis
dropColumns = c("Over18", "StandardHours", "EmployeeCount", "EmployeeNumber")

combinedEmployeeDataframe = combinedEmployeeDataframe[ , !(names(combinedEmployeeDataframe) %in% dropColumns)]
```

```{r}
combinedEmployeeDataframe = combinedEmployeeDataframe[,c(1,32,31,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30)]

apply(combinedEmployeeDataframe, 2, function(x) length(unique(x)))
ncol(combinedEmployeeDataframe)
```

```{r}
ncol(combinedEmployeeDataframe)
combinedEmployeeDataframe$LogMonthlyIncome = log(combinedEmployeeDataframe$MonthlyIncome)
combinedEmployeeDataframe
```

```{r}
# Feature engineer variables

# BusinessTravel into (0-Non-Travel,1-Travel_Rarely,2-Travel_Frequently)
combinedEmployeeDataframe$BusinessTravelNumeric <- as.numeric(factor(combinedEmployeeDataframe$BusinessTravel,
                                                        levels = c("Travel_Frequently", "Travel_Rarely", "Non-Travel"),
                                                        labels = c(2,1,0), ordered = TRUE))
```

```{r}
# Remove missing attrition values and create Knn/Naive Bayes models with top performing variables from ModelAnalysis.Rmd as well as feature engineered values from above
# save results to .csv file for further model analysis
combinedEmployeeDataframe

columnsForModelSelection = c("Attrition", "JobInvolvement", "JobLevel", "JobSatisfaction", "PerformanceRating", "StockOptionLevel", "TotalWorkingYears", "WorkLifeBalance", "BusinessTravelNumeric")

topPerformingVariablesDataframe = combinedEmployeeDataframe[,columnsForModelSelection]
topPerformingVariablesDataframe
```

```{r}
#Seperate the yes/no attrition observations into 2 dataframes
noAttritionTrainingDataframe = topPerformingVariablesDataframe[topPerformingVariablesDataframe$Attrition == 'No',]
yesAttritionTrainingDataframe = topPerformingVariablesDataframe[topPerformingVariablesDataframe$Attrition == 'Yes',]

trainingPercent = nrow(yesAttritionTrainingDataframe) / nrow(noAttritionTrainingDataframe)

maxKvalue = 5
iterations = 30

columnCombinations = c(2,3,4,5,6,7,8,9)

noAttritionTrainingDataframe
yesAttritionTrainingDataframe
```

```{r}
for(i in 1:length(columnCombinations)){
  resultsDataframe = data.frame(sensitivity = double(), specificity = double(), kValue = integer(), combination = character())
  columnCombinationsMatrix = combn(columnCombinations, i)
  for(j in 1:ncol(columnCombinationsMatrix)){
    for(k in 1:maxKvalue){
      iterationResultsDataframe = data.frame(sensitivity = double(), specificity = double(), kValue = integer(), combination = character())
      for(l in 1:iterations){
        trainingIndicies = sample(1:dim(noAttritionTrainingDataframe)[1], round(trainingPercent * dim(noAttritionTrainingDataframe)[1]))
        trainingDataSet = rbind(noAttritionTrainingDataframe[trainingIndicies,], yesAttritionTrainingDataframe)

        classifications = knn.cv(trainingDataSet[,columnCombinationsMatrix[,j]], trainingDataSet$Attrition, k=k, prob = TRUE)
        iterationResultsDataframe[nrow(iterationResultsDataframe) + 1,] = c(confusionMatrix(table(classifications, trainingDataSet$Attrition))$byClass[1], confusionMatrix(table(classifications, trainingDataSet$Attrition))$byClass[2], k, paste(columnCombinationsMatrix[,j], collapse = " "))
      }
      # Pass the mean sensitivity/specificity from the iterationResultsDataframe into resultsDataframe
      resultsDataframe[nrow(resultsDataframe) + 1,] = c(mean(as.numeric(iterationResultsDataframe$sensitivity)), mean(as.numeric(iterationResultsDataframe$specificity)), k, paste(columnCombinationsMatrix[,j], collapse = " "))
    }
  }
  fileLocation = paste("C:/SMU MS Data Science/DoingDataScience6306/EmployeeAttrition/SecondaryModelResults/KnnResults/Results1/Results", i, ".csv", sep="")
  write.csv(resultsDataframe, fileLocation, row.names = TRUE)
}

resultsDataframe
```

```{r}
# for(i in 1:2){
#   resultsDataframe = data.frame(sensitivity = double(), specificity = double(), kValue = integer(), combination = character())
#   columnCombinationsMatrix = combn(columnCombinations, i)
#   for(j in 1:ncol(columnCombinationsMatrix)){
#     for(k in 1:3){
#       iterationResultsDataframe = data.frame(sensitivity = double(), specificity = double(), kValue = integer(), combination = character())
#       for(l in 1:iterations){
#         trainingIndicies = sample(1:dim(noAttritionTrainingDataframe)[1], round(trainingPercent * dim(noAttritionTrainingDataframe)[1]))
#         trainingDataSet = rbind(noAttritionTrainingDataframe[trainingIndicies,], yesAttritionTrainingDataframe)
# 
#         classifications = knn.cv(trainingDataSet[,columnCombinationsMatrix[,j]], trainingDataSet$Attrition, k=k, prob = TRUE)
#         iterationResultsDataframe[nrow(iterationResultsDataframe) + 1,] = c(confusionMatrix(table(classifications, trainingDataSet$Attrition))$byClass[1], confusionMatrix(table(classifications, trainingDataSet$Attrition))$byClass[2], k, paste(columnCombinationsMatrix[,j], collapse = " "))
#       }
#       # Pass the mean sensitivity /specificity from the iterationResultsDataframe into resultsDataframe
#       resultsDataframe[nrow(resultsDataframe) + 1,] = c(mean(as.numeric(iterationResultsDataframe$sensitivity)), mean(as.numeric(iterationResultsDataframe$specificity)), k, paste(columnCombinationsMatrix[,j], collapse = " "))
#     }
#   }
# }
```

```{r}
# confusionMatrix(table(classifications, trainingDataSet$Attrition))
# confusionMatrix(table(classifications, trainingDataSet$Attrition))$byClass[1]
# confusionMatrix(table(classifications, trainingDataSet$Attrition))$byClass[2]
# resultsDataframe
```